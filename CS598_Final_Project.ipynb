{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a49f2f70725440bbbfc9fd8c667f8037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af2f5f5f6f1d4ca09e5218433ae3b28b",
              "IPY_MODEL_c90ef5509c2a4c41b20b472b49b9e5cb",
              "IPY_MODEL_3b9b66aa00fb4689b0a14923f2e114f1"
            ],
            "layout": "IPY_MODEL_fbdd17a4406649b18ec93d8f75534d51"
          }
        },
        "af2f5f5f6f1d4ca09e5218433ae3b28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f225843bf29d444b94886caa9d1bb910",
            "placeholder": "​",
            "style": "IPY_MODEL_ce95244dfcd64369989b1d354c8ca0c5",
            "value": "Map: 100%"
          }
        },
        "c90ef5509c2a4c41b20b472b49b9e5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111f328e184c49faa00500b5dea6a31f",
            "max": 1947,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95be500cc779440bb6c481f8e5995dd6",
            "value": 1947
          }
        },
        "3b9b66aa00fb4689b0a14923f2e114f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73ca41a97b24090a2dc0e1710349b46",
            "placeholder": "​",
            "style": "IPY_MODEL_2536ac4caabc4fb7b2f96bf7e7bf05f1",
            "value": " 1947/1947 [00:06&lt;00:00, 280.27 examples/s]"
          }
        },
        "fbdd17a4406649b18ec93d8f75534d51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f225843bf29d444b94886caa9d1bb910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce95244dfcd64369989b1d354c8ca0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111f328e184c49faa00500b5dea6a31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95be500cc779440bb6c481f8e5995dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d73ca41a97b24090a2dc0e1710349b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2536ac4caabc4fb7b2f96bf7e7bf05f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b203f73a9d4c04ac5bdd63c90acdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cd455705dfe4fb2925c723db8b0e4bc",
              "IPY_MODEL_c3d826dfd82a4e86a004b2d3953ec2e1",
              "IPY_MODEL_6fab31df0d3541d693d50c33ceca4bf5"
            ],
            "layout": "IPY_MODEL_2765eaf41f2b4bb5819db679f639c459"
          }
        },
        "1cd455705dfe4fb2925c723db8b0e4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf15c93d553468bb7a47a1b1d951262",
            "placeholder": "​",
            "style": "IPY_MODEL_6549d7a9342447978e456762f9a8fada",
            "value": "Map: 100%"
          }
        },
        "c3d826dfd82a4e86a004b2d3953ec2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656da114f4de41d88f215c03fd76fdd6",
            "max": 487,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a955af84b934ba1af4637f322b18025",
            "value": 487
          }
        },
        "6fab31df0d3541d693d50c33ceca4bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e4454089c44279bb907d5c302e9593",
            "placeholder": "​",
            "style": "IPY_MODEL_2bfc55d1802148bd9fb37d8bd39b03dc",
            "value": " 487/487 [00:02&lt;00:00, 179.65 examples/s]"
          }
        },
        "2765eaf41f2b4bb5819db679f639c459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf15c93d553468bb7a47a1b1d951262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6549d7a9342447978e456762f9a8fada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656da114f4de41d88f215c03fd76fdd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a955af84b934ba1af4637f322b18025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e4454089c44279bb907d5c302e9593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfc55d1802148bd9fb37d8bd39b03dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristiewong/CS598_FinalProject/blob/main/CS598_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci1ckDvFc3z3"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers==4.28.0 datasets==3.4.1 seqeval==1.2.2 torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import seqeval.metrics as seqeval_metrics"
      ],
      "metadata": {
        "id": "OmiTkGBidyT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# 1) Set a random seed\n",
        "#########################\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "id": "EaGMMoRRTlWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# 2) Hyperparameters & Config\n",
        "#########################\n",
        "model_checkpoint = \"bert-base-cased\"  # or \"bert-base-uncased\"\n",
        "batch_size = 8\n",
        "num_epochs = 3\n",
        "label_all_tokens = True  # Typically True in NER to label sub-tokens consistently"
      ],
      "metadata": {
        "id": "DB9olernToq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MIMIC-III Clinical Database Files\n",
        "!wget -r -N -c -np --user kevinlc221 --ask-password https://physionet.org/files/deidentifiedmedicaltext/1.0/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8m1YcZQmreY",
        "outputId": "40855b69-5de1-40ec-cf1b-ac36423e2783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password for user ‘kevinlc221’: ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "PHYSIONET_FILEPATH_RES = '/content/physionet.org/files/deidentifiedmedicaltext/1.0/id.res'\n",
        "PHYSIONET_FILEPATH = '/content/physionet.org/files/deidentifiedmedicaltext/1.0/id.text'"
      ],
      "metadata": {
        "id": "8Zu476N4mt1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_entire_record(f):\n",
        "    \"\"\"\n",
        "    Reads from file f until it encounters START_OF_RECORD,\n",
        "    then accumulates all lines until END_OF_RECORD.\n",
        "    Returns the full text of the record as one string,\n",
        "    or None if we reach EOF with no record found.\n",
        "    Skips blank lines outside records.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    inside_record = False\n",
        "\n",
        "    while True:\n",
        "        pos = f.tell()\n",
        "        line = f.readline()\n",
        "        if not line:\n",
        "            # EOF\n",
        "            break\n",
        "\n",
        "        line_stripped = line.strip()\n",
        "        if not inside_record:\n",
        "            # Look for START_OF_RECORD\n",
        "            if line_stripped.startswith(\"START_OF_RECORD\"):\n",
        "                inside_record = True\n",
        "            # otherwise, skip blank or irrelevant lines\n",
        "        else:\n",
        "            # We are inside a record\n",
        "            if \"END_OF_RECORD\" in line_stripped:\n",
        "                # End of this record\n",
        "                return \"\\n\".join(lines)\n",
        "            else:\n",
        "                # Accumulate non-empty lines\n",
        "                if line_stripped:\n",
        "                    lines.append(line_stripped)\n",
        "\n",
        "    # If we exit loop, we didn't find a full record\n",
        "    return None"
      ],
      "metadata": {
        "id": "-QuNuqRMgvP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "token_pattern = re.compile(r'(\\S*\\[\\*\\*.*?\\*\\*\\]\\S*|\\S+)', re.DOTALL)\n",
        "\n",
        "def tokenize_text_record(record_text):\n",
        "    \"\"\"\n",
        "    Simple whitespace split for the original text (id.text).\n",
        "    \"\"\"\n",
        "    # Or you can do something more advanced, but typically whitespace is fine\n",
        "    return record_text.split()\n",
        "\n",
        "def tokenize_res_record(record_text):\n",
        "    \"\"\"\n",
        "    Use a regex that merges everything containing [**...**] into a single token.\n",
        "    Example: \"([**Hospital 1**])\" => one token, \"He arrived [**Hospital 2**]\" => ...\n",
        "    \"\"\"\n",
        "    tokens = token_pattern.findall(record_text)\n",
        "    return tokens\n",
        "\n",
        "def is_placeholder(token):\n",
        "    \"\"\"\n",
        "    Returns True if this token is considered a placeholder\n",
        "    (it includes [** ... **] somewhere).\n",
        "    \"\"\"\n",
        "    return ('[**' in token and '**]' in token)"
      ],
      "metadata": {
        "id": "iZDS9PP2QK2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_record_tokens(text_tokens, res_tokens):\n",
        "    \"\"\"\n",
        "    Aligns all tokens in text_tokens (from id.text) with res_tokens (from id.res).\n",
        "    A single placeholder (or multiple consecutive placeholders) in res_tokens\n",
        "    can replace multiple text_tokens in id.text.\n",
        "\n",
        "    Returns: a list of labels (\"PHI\" or \"O\"), one for each token in text_tokens.\n",
        "\n",
        "    Assumptions:\n",
        "      - Normal tokens in res_tokens must appear verbatim in text_tokens\n",
        "        (used as anchors).\n",
        "      - Placeholders in res_tokens are detected by is_placeholder(token).\n",
        "      - All placeholders in a row map to a continuous region of text_tokens\n",
        "        labeled \"PHI\" until the next anchor or end of text_tokens.\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    i, j = 0, 0\n",
        "    len_text = len(text_tokens)\n",
        "    len_res  = len(res_tokens)\n",
        "\n",
        "    while i < len_text and j < len_res:\n",
        "        # If res_tokens[j] is a placeholder (or multiple placeholders in a row)\n",
        "        if is_placeholder(res_tokens[j]):\n",
        "            # Skip all consecutive placeholders\n",
        "            while j < len_res and is_placeholder(res_tokens[j]):\n",
        "                j += 1\n",
        "\n",
        "            # If we've consumed all res_tokens,\n",
        "            # label the remainder of text_tokens as PHI\n",
        "            if j == len_res:\n",
        "                while i < len_text:\n",
        "                    labels.append(\"PHI\")\n",
        "                    i += 1\n",
        "            else:\n",
        "                # We have a normal token anchor: res_tokens[j]\n",
        "                anchor = res_tokens[j]\n",
        "                # Label text_tokens as PHI until we find this anchor or run out\n",
        "                while i < len_text and text_tokens[i] != anchor:\n",
        "                    labels.append(\"PHI\")\n",
        "                    i += 1\n",
        "                # If we haven't run out, we presumably matched the anchor\n",
        "                # We'll handle it in the next iteration, so do NOT increment i here\n",
        "                # because we haven't actually labeled that anchor token yet.\n",
        "                # We'll let the loop handle it.\n",
        "        else:\n",
        "            # Normal token in res_tokens => must match text_tokens exactly\n",
        "            if text_tokens[i] != res_tokens[j]:\n",
        "                raise ValueError(\n",
        "                    f\"Mismatch: text_tokens[{i}]='{text_tokens[i]}' \"\n",
        "                    f\"vs res_tokens[{j}]='{res_tokens[j]}'\"\n",
        "                )\n",
        "            # If it matches, label it \"O\"\n",
        "            labels.append(\"O\")\n",
        "            i += 1\n",
        "            j += 1\n",
        "\n",
        "    # If we still have leftover text_tokens, label them \"O\"\n",
        "    # (or \"PHI\" if you expect placeholders to cover them).\n",
        "    while i < len_text:\n",
        "        labels.append(\"O\")\n",
        "        i += 1\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "9Mb3aGZciF_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_labeled_dataset(text_path, res_path):\n",
        "    \"\"\"\n",
        "    - Opens both files.\n",
        "    - Reads entire records from each (ignoring differences in line breaks).\n",
        "    - Tokenizes text vs. placeholders.\n",
        "    - Aligns them to produce \"PHI\"/\"O\" labels for the original text tokens.\n",
        "    - Returns a list of dicts: [{\"tokens\": [...], \"ner_tags\": [...]}].\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(text_path, \"r\", encoding=\"utf-8\") as ft, \\\n",
        "         open(res_path,  \"r\", encoding=\"utf-8\") as fr:\n",
        "\n",
        "        while True:\n",
        "            text_record = read_entire_record(ft)\n",
        "            res_record  = read_entire_record(fr)\n",
        "\n",
        "            if text_record is None or res_record is None:\n",
        "                # End if either file is done\n",
        "                break\n",
        "\n",
        "            # 1) Tokenize entire record\n",
        "            text_tokens = tokenize_text_record(text_record)\n",
        "            res_tokens  = tokenize_res_record(res_record)\n",
        "\n",
        "            # 2) Align\n",
        "            try:\n",
        "                labels = align_record_tokens(text_tokens, res_tokens)\n",
        "            except ValueError as e:\n",
        "                # If mismatch, you might skip this record or handle differently\n",
        "                print(f\"Warning: mismatch in record. Skipping.\\n{e}\")\n",
        "                continue\n",
        "\n",
        "            # 3) Store\n",
        "            records.append({\n",
        "                \"tokens\": text_tokens,\n",
        "                \"ner_tags\": labels\n",
        "            })\n",
        "\n",
        "    return records"
      ],
      "metadata": {
        "id": "DjlON1kagzj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 5) Parse the entire dataset\n",
        "################################################################################\n",
        "\n",
        "all_records = build_labeled_dataset(PHYSIONET_FILEPATH, PHYSIONET_FILEPATH_RES)\n",
        "print(f\"Total parsed records: {len(all_records)}\")\n",
        "# Each element looks like: {\"tokens\": [...], \"ner_tags\": [...]}\n",
        "print(all_records[0][\"tokens\"])\n",
        "print(all_records[0][\"ner_tags\"])\n",
        "\n",
        "# -- Use only a SUBSET for faster training, e.g. 200 records --\n",
        "# subset_size = 200  # <-- Adjust if you want more or fewer\n",
        "# all_records = all_records[:subset_size]\n",
        "# print(f\"Using only the first {subset_size} records to speed up training...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM486BvJm016",
        "outputId": "8fba0a60-5d23-4f14-a7fc-fd39766225cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parsed records: 2434\n",
            "['O:', '58', 'YEAR', 'OLD', 'FEMALE', 'ADMITTED', 'IN', 'TRANSFER', 'FROM', 'CALVERT', 'HOSPITAL', 'FOR', 'MENTAL', 'STATUS', 'CHANGES', 'POST', 'FALL', 'AT', 'HOME', 'AND', 'CONTINUED', 'HYPOTENSION', 'AT', 'CALVERT', 'HOSPITAL', 'REQUIRING', 'DOPAMINE;', 'PMH:', 'CAD,', 'S/P', 'MI', '1992;', 'LCX', 'PTCA;', '3V', 'CABG', 'WITH', 'MVR;', 'CMP;', 'AFIB-', 'AV', 'NODE', 'ABLATION;', 'PERM', 'PACER-', 'DDD', 'MODE;', 'PULM', 'HTN;', 'PVD;', 'NIDDM;', 'HPI:', '2', 'WEEK', 'HISTORY', 'LEG', 'WEAKNESS;', '7/22', 'FOUND', 'BY', 'HUSBAND', 'ON', 'FLOOR-', 'AWAKE,', 'BUT', 'MENTAL', 'STATUS', 'CHANGES;', 'TO', 'CALVERT', 'HOSPITAL', 'ER-', 'TO', 'THEIR', 'ICU;', 'HEAD', 'CT-', 'NEG', 'FOR', 'BLEED;', 'VQ', 'SCAN-', 'NEG', 'FOR', 'PE;', 'ECHO-', 'GLOBAL', 'HYPOKINESIS;', 'EF', 'EST', '20%;', 'R/O', 'FOR', 'MI;', 'DIGOXIN', 'TOXIC', 'WITH', 'HYPERKALEMIA-', 'KAYEXALATE,', 'DEXTROSE,', 'INSULIN;', 'RENAL', 'INSUFFICIENCY-', 'BUN', '54,', 'CR', '2.8;', 'INR', '7', '(', 'ON', 'COUMADIN', 'AT', 'HOME);', '7/23', 'AT', 'CALVERT-', '2', 'FFP,', '2', 'UNITS', 'PRBC,', 'VITAMIN', 'K;', 'REFERRED', 'TO', 'GH.', 'ARRIVED', 'IN', 'TRANSFER', 'APPROX.', '2130;', 'IN', 'NO', 'MAJOR', 'DISTRESS;', 'DOPAMINE', 'TAPER,', 'THEN', 'DC;', 'NS', 'FLUID', 'BOLUS', 'GIVEN', 'WITH', 'IMPROVEMENT', 'IN', 'BP', 'RANGE;', 'SEE', 'FLOW', 'SHEET', 'SECTION', 'FOR', 'CLINICAL', 'INFORMATION;', 'A:', 'NO', 'HEMODYNAMIC', 'COMPROMISE', 'SINCE', 'TRANSFER;', 'TOLERATING', 'DOPAMINE', 'DC;', 'P:', 'TREND', 'BP', 'RANGE;', 'OBSERVE', 'FOR', 'PRECIPITOUS', 'HYPOTENSION.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'O', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PHI', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 6) Train/Test Split\n",
        "#\n",
        "#    The snippet below does a simple random 80/20 split for demonstration.\n",
        "#    If you have an official split or want to do cross-validation, adapt this part.\n",
        "################################################################################\n",
        "\n",
        "random.shuffle(all_records)\n",
        "split_idx = int(0.8 * len(all_records))\n",
        "train_records = all_records[:split_idx]\n",
        "test_records  = all_records[split_idx:]\n",
        "\n",
        "train_dataset = Dataset.from_list(train_records)\n",
        "test_dataset  = Dataset.from_list(test_records)\n",
        "\n",
        "physionet_dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\":  test_dataset\n",
        "})\n",
        "\n",
        "print(\"Train size:\", len(physionet_dataset[\"train\"]))\n",
        "print(\"Test size: \", len(physionet_dataset[\"test\"]))"
      ],
      "metadata": {
        "id": "Th0ZTxu7m2YB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241cdefd-beba-41a3-9bed-0614f89bc29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1947\n",
            "Test size:  487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 7) Build label mappings\n",
        "#\n",
        "#    In this simple example, we have only two labels: [\"O\", \"PHI\"].\n",
        "#    If you adapt your logic to detect multiple entity types, add them all here.\n",
        "################################################################################\n",
        "\n",
        "unique_tags = [\"O\", \"PHI\"]\n",
        "tag2id = {tag: i for i, tag in enumerate(unique_tags)}\n",
        "id2tag = {i: tag for i, tag in enumerate(unique_tags)}\n",
        "print(\"tag2id:\", tag2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh-BlY1Jm3nd",
        "outputId": "b6b27266-001d-4c5f-cccc-1ce6bd1a3b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag2id: {'O': 0, 'PHI': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 8) Tokenize and Align Labels\n",
        "#\n",
        "#    Because the notes are already \"tokenized\" at the whitespace level,\n",
        "#    we can use the tokenizer with `is_split_into_words=True`.\n",
        "#    We'll replicate each label for subword tokens (common in NER).\n",
        "################################################################################\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-cased\"  # or \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOvUHOyHm5np",
        "outputId": "c064aeb4-4d09-4e91-8ae6-a28a67ad0b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    word_ids_batch = []\n",
        "\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # subword->word mapping\n",
        "        aligned_labels = []\n",
        "\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                # This is typically a special token => mark as -100\n",
        "                aligned_labels.append(-100)\n",
        "            else:\n",
        "                aligned_labels.append(tag2id[labels[word_id]])\n",
        "        new_labels.append(aligned_labels)\n",
        "        word_ids_batch.append(word_ids)\n",
        "\n",
        "    # Save subword labels\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    # Also store the word_ids so we can reconstruct original words\n",
        "    tokenized_inputs[\"word_ids\"] = word_ids_batch\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "processed_dataset = physionet_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=[\"tokens\", \"ner_tags\"],  # remove original columns post-processing\n",
        ")"
      ],
      "metadata": {
        "id": "eqGQqtlXm6_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a49f2f70725440bbbfc9fd8c667f8037",
            "af2f5f5f6f1d4ca09e5218433ae3b28b",
            "c90ef5509c2a4c41b20b472b49b9e5cb",
            "3b9b66aa00fb4689b0a14923f2e114f1",
            "fbdd17a4406649b18ec93d8f75534d51",
            "f225843bf29d444b94886caa9d1bb910",
            "ce95244dfcd64369989b1d354c8ca0c5",
            "111f328e184c49faa00500b5dea6a31f",
            "95be500cc779440bb6c481f8e5995dd6",
            "d73ca41a97b24090a2dc0e1710349b46",
            "2536ac4caabc4fb7b2f96bf7e7bf05f1",
            "08b203f73a9d4c04ac5bdd63c90acdca",
            "1cd455705dfe4fb2925c723db8b0e4bc",
            "c3d826dfd82a4e86a004b2d3953ec2e1",
            "6fab31df0d3541d693d50c33ceca4bf5",
            "2765eaf41f2b4bb5819db679f639c459",
            "edf15c93d553468bb7a47a1b1d951262",
            "6549d7a9342447978e456762f9a8fada",
            "656da114f4de41d88f215c03fd76fdd6",
            "8a955af84b934ba1af4637f322b18025",
            "09e4454089c44279bb907d5c302e9593",
            "2bfc55d1802148bd9fb37d8bd39b03dc"
          ]
        },
        "outputId": "6e197ad3-f5b5-490c-cb73-e28b97792e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1947 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a49f2f70725440bbbfc9fd8c667f8037"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/487 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08b203f73a9d4c04ac5bdd63c90acdca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf  # for example\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPdwm2vuuGJk",
        "outputId": "094db79c-f138-4c57-b56e-1f8cc370501b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.11/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel, BertPreTrainedModel, BertConfig\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BertCRF(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "    BERT + CRF for token classification using torchcrf.\n",
        "    Returns:\n",
        "      (loss, decoded_tensor) if labels are provided\n",
        "      (decoded_tensor,) if labels=None\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.hidden2label = nn.Linear(config.hidden_size, self.num_labels)\n",
        "        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        last_encoder_layer = outputs[0]  # shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # Project to tag space\n",
        "        last_encoder_layer = self.dropout(last_encoder_layer)\n",
        "        emissions = self.hidden2label(last_encoder_layer)  # (batch_size, seq_len, num_labels)\n",
        "\n",
        "        # Build a mask for CRF\n",
        "        if labels is not None:\n",
        "            # Typical HF practice: -100 = \"ignore\"\n",
        "            mask = (labels >= 0)  # shape: (batch_size, seq_len), bool\n",
        "            # If a label is -100, zero it out for CRF\n",
        "            labels = labels * mask\n",
        "        else:\n",
        "            # Use attention_mask if no labels\n",
        "            # (assuming 1/0 meaning valid/invalid tokens)\n",
        "            if attention_mask is not None:\n",
        "                mask = attention_mask.bool()  # shape: (batch_size, seq_len)\n",
        "            else:\n",
        "                mask = None\n",
        "\n",
        "        # ---- FIX CRF \"first timestep\" error by ensuring first token is unmasked ----\n",
        "        #   If your dataset always has at least 1 token, forcibly set mask[:, 0] = True\n",
        "        if mask is not None and mask.shape[1] > 0:\n",
        "            mask[:, 0] = True\n",
        "\n",
        "        # CRF decoding => a list of lists of token indices\n",
        "        best_paths = self.crf.decode(emissions, mask=mask)\n",
        "\n",
        "        # Convert each best_path list to a padded tensor of shape [B, max_len]\n",
        "        max_len = max(len(p) for p in best_paths) if best_paths else 0\n",
        "        batch_size = emissions.size(0)\n",
        "        best_paths_tensor = torch.full(\n",
        "            (batch_size, max_len),\n",
        "            -1,\n",
        "            dtype=torch.long,\n",
        "            device=emissions.device\n",
        "        )\n",
        "        for i, path in enumerate(best_paths):\n",
        "            best_paths_tensor[i, :len(path)] = torch.tensor(path, device=emissions.device)\n",
        "\n",
        "        # Return format suitable for HF Trainer\n",
        "        # If labels were provided, also compute negative log-likelihood\n",
        "        if labels is not None:\n",
        "            # TorchCRF returns log_likelihood for each sample (summed over the batch)\n",
        "            log_likelihood = self.crf(emissions, tags=labels, mask=mask)\n",
        "            loss = -log_likelihood  # the CRF log-likelihood is the negative loss\n",
        "            return (loss, best_paths_tensor)\n",
        "        else:\n",
        "            return (best_paths_tensor,)\n"
      ],
      "metadata": {
        "id": "tcBSBPYHslJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 9) Model and Trainer Setup\n",
        "################################################################################\n",
        "\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "num_labels = len(unique_tags)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
        "config = BertConfig.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
        "model = BertCRF.from_pretrained(model_checkpoint, config=config)\n",
        "\n",
        "batch_size = 8\n",
        "num_epochs = 3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert-deid-physionet-demo\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",  # Avoids default W&B\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    seed=SEED,\n",
        ")"
      ],
      "metadata": {
        "id": "Gevo605Om96F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f6933f-aef4-475f-cc25-07b26bea56c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertCRF: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertCRF from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertCRF from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertCRF were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['hidden2label.bias', 'hidden2label.weight', 'crf.transitions', 'crf.end_transitions', 'crf.start_transitions']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 10) Metrics (Precision, Recall, F1, Accuracy via seqeval)\n",
        "################################################################################\n",
        "\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions, labels = eval_preds\n",
        "\n",
        "    # Convert tensors to numpy if needed\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    true_preds = []\n",
        "    true_labels = []\n",
        "\n",
        "    for pred_seq, gold_seq in zip(predictions, labels):\n",
        "        # Filter out positions where gold_seq == -100\n",
        "        filtered_preds = []\n",
        "        filtered_labels = []\n",
        "        for p, g in zip(pred_seq, gold_seq):\n",
        "            if g == -100:\n",
        "                continue\n",
        "            filtered_preds.append(p)\n",
        "            filtered_labels.append(g)\n",
        "\n",
        "        # 1) Map integers to strings: e.g. 0->\"O\", 1->\"PHI\"\n",
        "        pred_str_seq = [id2tag[x] for x in filtered_preds]\n",
        "        gold_str_seq = [id2tag[x] for x in filtered_labels]\n",
        "\n",
        "        true_preds.append(pred_str_seq)\n",
        "        true_labels.append(gold_str_seq)\n",
        "\n",
        "    # 2) Now use seqeval with string tags\n",
        "    precision = precision_score(true_labels, true_preds)\n",
        "    recall    = recall_score(true_labels, true_preds)\n",
        "    f1        = f1_score(true_labels, true_preds)\n",
        "    accuracy  = accuracy_score(true_labels, true_preds)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\":    recall,\n",
        "        \"f1\":        f1,\n",
        "        \"accuracy\":  accuracy,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5XF8oo_mnA2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 11) Trainer\n",
        "################################################################################\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "uOdtaQaSnCYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 12) Train\n",
        "################################################################################\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "SOxgib-rU-LJ",
        "outputId": "b77a45ba-44ad-4090-a1ee-f79ca17fd297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='255' max='732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [255/732 06:04 < 11:27, 0.69 it/s, Epoch 1.04/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>73.374100</td>\n",
              "      <td>81.733940</td>\n",
              "      <td>0.572072</td>\n",
              "      <td>0.395639</td>\n",
              "      <td>0.467772</td>\n",
              "      <td>0.992169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PHI seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# 13) Evaluate\n",
        "################################################################################\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Evaluation metrics:\", metrics)"
      ],
      "metadata": {
        "id": "LKJfOf0fpzbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose you already have your (input_ids, attention_mask) for a single sentence:\n",
        "sentence = \"John Smith arrived at the New York Hospital.\"\n",
        "encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "# The Trainer expects a Dataset object with lists (one entry per example).\n",
        "# So we convert your single example to Python lists of length 1:\n",
        "sample_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": [encoding[\"input_ids\"][0].tolist()],\n",
        "    \"attention_mask\": [encoding[\"attention_mask\"][0].tolist()]\n",
        "    # If your model is trained with token_type_ids, add them similarly.\n",
        "})\n",
        "\n",
        "predictions, label_ids, metrics = trainer.predict(sample_dataset)\n",
        "predictions = predictions[0]  # shape [seq_len]\n",
        "\n",
        "# Convert input_ids (list of int) back to tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(sample_dataset[0][\"input_ids\"])\n",
        "\n",
        "# Suppose predictions is shape [seq_len]\n",
        "pred_labels = []\n",
        "for i, pred_id in enumerate(predictions):\n",
        "    # skip special tokens if needed\n",
        "    if tokens[i] in (\"[CLS]\", \"[SEP]\"):\n",
        "        continue\n",
        "    pred_labels.append((tokens[i], id2tag[pred_id]))\n",
        "print(\"=== Single Sentence Prediction ===\")\n",
        "for tok, lab in pred_labels:https://github.com/kristiewong/30-seconds-of-swift-code/blob/master/CS598%20Final%20Project.ipynb\n",
        "    print(f\"{tok:15} => {lab}\")\n"
      ],
      "metadata": {
        "id": "-waxmZTnZq0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"/content/final_ner_model\")"
      ],
      "metadata": {
        "id": "YTAtQiZOo43F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/model.zip /content/final_ner_model"
      ],
      "metadata": {
        "id": "f3mBmwlz3MVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. Install dependencies\n",
        "!pip install transformers datasets seqeval --quiet\n",
        "\n",
        "# ✅ 2. Imports\n",
        "import torch\n",
        "from datasets import DatasetDict, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ✅ 3. Define label mappings\n",
        "unique_tags = [\"O\", \"PHI\"]\n",
        "tag2id = {tag: i for i, tag in enumerate(unique_tags)}\n",
        "id2tag = {i: tag for tag, i in tag2id.items()}\n",
        "\n",
        "# ✅ 4. Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True)\n",
        "\n",
        "# ✅ 5. Tokenization function\n",
        "\n",
        "def tokenize_and_align_labels(examples, tokenizer, tag2id):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        aligned_labels = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                aligned_labels.append(-100)\n",
        "            else:\n",
        "                aligned_labels.append(tag2id[labels[word_id]])\n",
        "        new_labels.append(aligned_labels)\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# ✅ 6. Load your processed dataset here\n",
        "# Replace with actual load if not already present\n",
        "# processed_dataset = DatasetDict(...)\n",
        "\n",
        "# ✅ 7. Compute metrics\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = torch.tensor(logits).argmax(dim=-1).numpy()\n",
        "    labels = torch.tensor(labels).numpy()\n",
        "\n",
        "    true_preds, true_labels = [], []\n",
        "    for pred_seq, label_seq in zip(predictions, labels):\n",
        "        p_seq, l_seq = [], []\n",
        "        for p, l in zip(pred_seq, label_seq):\n",
        "            if l != -100:\n",
        "                p_seq.append(id2tag[p])\n",
        "                l_seq.append(id2tag[l])\n",
        "        true_preds.append(p_seq)\n",
        "        true_labels.append(l_seq)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(true_labels, true_preds),\n",
        "        \"recall\": recall_score(true_labels, true_preds),\n",
        "        \"f1\": f1_score(true_labels, true_preds),\n",
        "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
        "    }\n",
        "\n",
        "# ✅ 8. Define model (Vanilla BERT)\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2id))\n",
        "\n",
        "# ✅ 9. Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-deid-vanilla\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# ✅ 10. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# ✅ 11. Train and Evaluate\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Evaluation metrics:\", metrics)\n"
      ],
      "metadata": {
        "id": "oG5URxwZna5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KLoI8fDEnLXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}